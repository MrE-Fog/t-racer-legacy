{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "camera_records = glob.glob('images/camera_*.yuv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_yuv_to_jpg(yuv_path, folder, w, h):\n",
    "    # Read entire file into YUV\n",
    "    YUV = np.fromfile(yuv_path,dtype='uint8')\n",
    "    Y = YUV[0:w*h].reshape(h,w)\n",
    "    im = Image.fromarray(Y)\n",
    "    file_name = yuv_path.split('/')[1].split('.yuv')[0]\n",
    "    im.save(folder + '/' + file_name + '.jpg')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_yuv_to_arr(yuv_path, w, h):\n",
    "    YUV = np.fromfile(yuv_path,dtype='uint8')\n",
    "    Y = YUV[0:w*h].reshape(h,w)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # one time converstion from yuv to jpg\n",
    "# for record in camera_records:\n",
    "#     write_yuv_to_jpg(record, 'images', 256, 154)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "control_records = glob.glob('images/control_*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_records = [record.split('_', 1)[1] for record in control_records]\n",
    "time_stamps = [record.split('.txt', 1)[0] for record in tmp_records]\n",
    "control_time_stamps = list(map(float, time_stamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1]\n",
    "    else:\n",
    "        return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_control_time_stamps = np.sort(control_time_stamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steers = []\n",
    "accs = []\n",
    "imgs = []\n",
    "for record in camera_records:\n",
    "    camera_time_stamp = float(record.split('_', 1)[1].split('.yuv', 1)[0])\n",
    "    control_time_stamp = find_nearest(sorted_control_time_stamps, camera_time_stamp)\n",
    "    path = 'images/control_' + str(control_time_stamp) + '.txt'\n",
    "    with open(path) as control_file:\n",
    "        control_str = control_file.readline()\n",
    "        steer = int(control_str.split('x')[0].split('s')[1])\n",
    "        acc = int(control_str.split('x')[1].split('a')[1])\n",
    "        steers = np.append(steers, steer)\n",
    "        accs = np.append(accs, acc)\n",
    "        imgs = np.append(imgs, record.split('/', 1)[1].split('.yuv')[0] + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['file_name'] = imgs\n",
    "df['throttle'] = accs\n",
    "df['angle'] = steers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only using throttle over or equal 1500 to filter out unexpected stoppings along the track\n",
    "df = df.loc[df['throttle'] >= 1500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['throttle'] = (df['throttle'] - 1500) / (1800 - 1500)\n",
    "df['angle'] = (df['angle'] - 60) / (140 - 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_loader = ImageDataGenerator()\n",
    "\n",
    "train_generator = image_loader.flow_from_dataframe(dataframe=df_train, directory=\"images\", x_col='file_name', y_col=['throttle', 'angle'], target_size=(224, 224), color_mode='rgb', class_mode='other', batch_size=32)\n",
    "\n",
    "val_generator = image_loader.flow_from_dataframe(dataframe=df_val, directory='images', x_col='file_name', y_col=['throttle', 'angle'], target_size=(224, 224), color_mode='rgb', class_mode='other', batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Input, Cropping2D, Dense\n",
    "from keras.layers import Dropout, GlobalAveragePooling2D\n",
    "from keras.layers import Convolution2D, Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import Model\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=VGG16(input_shape=(224, 224, 3), weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(2, activation='linear')(x) #final layer with linear activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:19]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "  print(i,layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=100,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=20,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('models/model-vgg16-transfer.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6 (myenv1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
